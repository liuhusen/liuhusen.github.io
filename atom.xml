<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>藏书阁</title>
  <icon>https://www.gravatar.com/avatar/f891a51eb4e19375142db2543d2003e2</icon>
  <subtitle>奔跑</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://liuhusen.com/"/>
  <updated>2019-04-08T08:21:55.685Z</updated>
  <id>https://liuhusen.com/</id>
  
  <author>
    <name>Mr.Liu</name>
    <email>I_striving@163.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>springboot之日志配置记录</title>
    <link href="https://liuhusen.com/2019/01/22/springboot%E4%B9%8B%E6%97%A5%E5%BF%97%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95/"/>
    <id>https://liuhusen.com/2019/01/22/springboot之日志配置记录/</id>
    <published>2019-01-22T11:31:20.000Z</published>
    <updated>2019-04-08T08:21:55.685Z</updated>
    
    <content type="html"><![CDATA[<pre><code>springboot ---   日志使用首先，假设我们要开发一个大型系统；  那么关于日志： 1、System.out.println(&quot;&quot;)；将关键数据打印在控制台；去掉？写在一个文件？ 2、框架来记录系统的一些运行时信息；日志框架 ； zhanglogging.jar； 3、高大上的几个功能？异步模式？自动归档？xxxx？ zhanglogging-good.jar？ 4、将以前框架卸下来？换上新的框架，重新修改之前相关的API；zhanglogging-prefect.jar； 5、JDBC---数据库驱动； 写了一个统一的接口层；日志门面（日志的一个抽象层）；logging-abstract.jar； 给项目中导入具体的日志实现就行了；我们之前的日志框架都是实现的抽象层；所见到过的市面上的日志框架如下；     JUL、JCL、Jboss-logging、logback、log4j、log4j2、slf4j.... 日志门面 （日志的抽象层）                                          日志实现 JCL（Jakarta Commons Logging）、                                   Log4j  、JUL（java.util.logging）         SLF4j（Simple Logging Facade for Java）、                            Log4j2 、  Logback jboss-logging         左边选一个门面（抽象层）、右边来选一个实现； 日志门面： SLF4J； 日志实现：Logback； SpringBoot：底层是Spring框架，Spring框架默认是用 JCL； 默认情况下，Spring Boot会用Logback来记录日志，并用INFO级别输出到控制台。在运行应用程序和其他例子时，你应该已经看到很多INFO级别的日志了。 添加日志依赖 假如maven依赖中添加了spring-boot-starter-logging：     &lt;dependency&gt;         &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;         &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;     &lt;/dependency&gt; 但是呢，实际开发中我们不需要直接添加该依赖。     你会发现spring-boot-starter其中包含了 spring-boot-starter-logging，该依赖内容就是 Spring Boot 默认的日志框架 logback。    工程中有用到了web，而web依赖包含了spring-boot-starter，最终我只要引入web即可。     &lt;dependency&gt;         &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;         &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;     &lt;/dependency&gt; 控制台输出日志级别从低到高分为：TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL 在选择相应的日志实现后，具体操作如下  1.依赖配置：使用如下：     1. 如果使用 SLF4j 做门面 和logback做日志实现；        那么，由于springboot默认情况下会用Logback来记录日志，所以无需多余配置，但如果想将日志打印在指定的文件里，请同意看后面的阐述     2. 如果使用 SLF4j 做门面 和 Log4j2 做日志实现；         那么首先排除springboot默认的日志实现，并且加入log4j2的依赖  ----如下：                  &lt;dependency&gt;                     &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                     &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;                     &lt;exclusions&gt;                         &lt;exclusion&gt;                             &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;                             &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                         &lt;/exclusion&gt;                     &lt;/exclusions&gt;                 &lt;/dependency&gt;                &lt;dependency&gt;                     &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                     &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;                &lt;/dependency&gt; 2.代码里引用：注意：开发的时候，日志记录方法的调用，不应该来直接调用日志的实现类，而是调用日志抽象层里面的方法；               给系统里面导入slf4j的jar和 logback的实现jar                 图示；                     import org.slf4j.Logger;                     import org.slf4j.LoggerFactory;                     public class HelloWorld {                       public static void main(String[] args) {                         Logger logger = LoggerFactory.getLogger(HelloWorld.class);                         logger.info(&quot;Hello World&quot;);                       }                     }  前面说过    想把日志打印在指定的文件里，还有加入其它更详细的配置，看这里：     日志输出格式：         %d表示日期时间，                 %thread表示线程名，                 %‐5level：级别从左显示5个字符宽度                 %logger{50} 表示logger名字最长50个字符，否则按照句点分割。                  %msg：日志消息，                 %n是换行符                 如：d{yyyy‐MM‐dd HH:mm:ss.SSS} [%thread] %‐5level %logger{50} ‐ %msg%n             SpringBoot修改日志的默认配置         1.             logging.level.com.atguigu=trace             #logging.path=             # 不指定路径在当前项目下生成springboot.log日志             # 可以指定完整的路径；             #logging.file=G:/springboot.log             # 在当前磁盘的根路径下创建spring文件夹和里面的log文件夹；使用 spring.log 作为默认文件             logging.path=/spring/log             #  在控制台输出的日志的格式             logging.pattern.console=%d{yyyy‐MM‐dd} [%thread] %‐5level %logger{50} ‐ %msg%n             # 指定文件中日志输出的格式             logging.pattern.file=%d{yyyy‐MM‐dd} === [%thread] === %‐5level === %logger{50} ==== %msg%n             2、指定配置             给类路径下放上每个日志框架自己的配置文件即可；SpringBoot就不使用他默认配置的了             Logging System                         Customization             Logback                                logback-spring.xml ,  logback-spring.groovy ,  logback.xml or logback.groovy             Log4j2                                 log4j2-spring.xml or  log4j2.xml             JDK (Java Util Logging)                logging.properties             logback.xml：直接就被日志框架识别了；             logback-spring.xml：日志框架就不直接加载日志的配置项，由SpringBoot解析日志配置，                         Spring Boot官方推荐优先使用带有-spring的文件名作为你的日志配置（如使用logback-spring.xml，而不是logback.xml），             命名为logback-spring.xml的日志配置文件，spring boot可以为它添加一些spring boot特有的配置项（下面会提到）。              默认的命名规则，并且放在 src/main/resources 下面即可             如果你即想完全掌控日志配置，但又不想用logback.xml作为Logback配置的名字，application.yml可以通过logging.config属性指定自定义的名字：             logging.config=classpath:logging-config.xml             1             虽然一般并不需要改变配置文件的名字，但是如果你想针对不同运行时Profile使用不同的日志配置，这个功能会很有用。              一般不需要这个属性，而是直接在logback-spring.xml中使用springProfile配置，不需要logging.config指定不同环境使用不同配置文件。             springProfile配置在下面介绍。             &lt;springProfile name=&quot;staging&quot;&gt;                 &lt;!‐‐ configuration to be enabled when the &quot;staging&quot; profile is active ‐‐&gt;                        可以指定某段配置只在某个环境下生效               &lt;/springProfile&gt;             如：                &lt;appender name=&quot;stdout&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;                         &lt;!‐‐                         日志输出格式：                         %d表示日期时间，                                     %thread表示线程名，                                     %‐5level：级别从左显示5个字符宽度                                     %logger{50} 表示logger名字最长50个字符，否则按照句点分割。                                      %msg：日志消息，                                     %n是换行符                                     ‐‐&gt;                         &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt;                             &lt;springProfile name=&quot;dev&quot;&gt;                                 &lt;pattern&gt;%d{yyyy‐MM‐dd HH:mm:ss.SSS} ‐‐‐‐&gt; [%thread] ‐‐‐&gt; %‐5level%logger{50} ‐ %msg%n&lt;/pattern&gt;                             &lt;/springProfile&gt;                             &lt;springProfile name=&quot;!dev&quot;&gt;                                 &lt;pattern&gt;%d{yyyy‐MM‐dd HH:mm:ss.SSS} ==== [%thread] ==== %‐5level%logger{50} ‐ %msg%n&lt;/pattern&gt;                             &lt;/springProfile&gt;                         &lt;/layout&gt;                &lt;/appender&gt;                如果使用logback.xml作为日志配置文件，还要使用profile功能，会有以下错误                 no applicable action for [springProfile]             logback-spring.xml配置文件里配置教程：                  根节点包含的属性                     scan:当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。                     scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。                     当scan为true时，此属性生效。默认的时间间隔为1分钟。                     debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。                     根节点&lt;configuration&gt;有5个子节点，下面一一会详细介绍                         子节点一                               &lt;root&gt;                                 root节点是必选节点，用来指定最基础的日志输出级别，只有一个level属性。                                 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF，不能设置为INHERITED或者同义词NULL。                                  默认是DEBUG。                                  可以包含零个或多个元素，标识这个appender将会添加到这个loger。                                 &lt;root level=&quot;debug&quot;&gt;                                   &lt;appender-ref ref=&quot;console&quot; /&gt;                                   &lt;appender-ref ref=&quot;file&quot; /&gt;                              &lt;/root&gt;                         子节点二：&lt;contextName&gt; 设置上下文名称                              每个logger都关联到logger上下文，默认上下文名称为“default”。但可以使用设置成其他名字，                              用于区分不同应用程序的记录。一旦设置，不能修改,可以通过%contextName来打印日志上下文名称，                              一般来说我们不用这个属性，可有可无。                              &lt;contextName&gt;logback&lt;/contextName&gt;                         子节点三：&lt;property&gt; 设置变量                             用来定义变量值的标签， 有两个属性，name和value；其中name的值是变量的名称，value的值时变量定义的值。                             通过定义的值会被插入到logger上下文中。定义变量后，可以使“${}”来使用变量。                             &lt;property name=&quot;logback.logdir&quot; value=&quot;/Users/inke/dev/log/tomcat&quot;/&gt;                             &lt;property name=&quot;logback.appname&quot; value=&quot;app&quot;/&gt;                             1                             2                             这里可以看后通过 application.yml 传递参数过来。                         子节点四：&lt;appender&gt;                             appender用来格式化日志输出节点，有俩个属性name和class，class用来指定哪种输出策略，                             常用就是控制台输出策略和文件输出策略。                             控制台输出ConsoleAppender：                             示例一：                                  &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;                                     &lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt;                                         &lt;contextName&gt;logback-demo&lt;/contextName&gt;                                         &lt;!--输出到控制台 ConsoleAppender--&gt;                                         &lt;appender name=&quot;consoleLog1&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;                                             &lt;!--展示格式 layout--&gt;                                             &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt;                                                 &lt;pattern&gt;%d -1 %msg%n&lt;/pattern&gt;                                             &lt;/layout&gt;                                         &lt;/appender&gt;                                         &lt;!--输出到控制台 ConsoleAppender--&gt;                                         &lt;appender name=&quot;consoleLog2&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;                                             &lt;encoder&gt;                                                 &lt;pattern&gt;%d -2 %msg%n&lt;/pattern&gt;                                             &lt;/encoder&gt;                                         &lt;/appender&gt;                                         &lt;!--指定最基础的日志输出级别--&gt;                                         &lt;root level=&quot;INFO&quot;&gt;                                             &lt;!--appender将会添加到这个loger--&gt;                                             &lt;appender-ref ref=&quot;consoleLog1&quot;/&gt;                                             &lt;appender-ref ref=&quot;consoleLog2&quot;/&gt;                                         &lt;/root&gt;                                     &lt;/configuration&gt;                             可以看到layout和encoder，都可以将事件转换为格式化后的日志记录，但是控制台输出使用layout，文件输出使用encoder，                             具体原因可以看我百度到的这个答案，就不特意去说了http://blog.csdn.net/cw_hello1/article/details/51969554                             &lt;encoder&gt;表示对日志进行编码：                                 %d{HH: mm:ss.SSS}——日志输出时间                                 %thread——输出日志的进程名字，这在Web应用以及异步任务处理中很有用                                 %-5level——日志级别，并且使用5个字符靠左对齐                                 %logger{36}——日志输出者的名字                                 %msg——日志消息                                 %n——平台的换行符                                  ThresholdFilter为系统定义的拦截器，例如我们用ThresholdFilter来过滤掉ERROR级别以下的日志不输出到文件中。                                 如果不用记得注释掉，不然你控制台会发现没日志                             输出到文件 RollingFileAppender                             另一种常见的日志输出到文件，随着应用的运行时间越来越长，日志也会增长的越来越多，                             将他们输出到同一个文件并非一个好办法。RollingFileAppender用于切分文件日志：                             &lt;appender name=&quot;fileInfoLog&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;                                 &lt;!--如果只是想要 Info 级别的日志，只是过滤 info 还是会输出 Error 日志，因为 Error 的级别高，                                 所以我们使用下面的策略，可以避免输出 Error 的日志--&gt;                                 &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;                                     &lt;!--过滤 Error--&gt;                                     &lt;level&gt;ERROR&lt;/level&gt;                                     &lt;!--匹配到就禁止--&gt;                                     &lt;onMatch&gt;DENY&lt;/onMatch&gt;                                     &lt;!--没有匹配到就允许--&gt;                                     &lt;onMismatch&gt;ACCEPT&lt;/onMismatch&gt;                                 &lt;/filter&gt;                                 &lt;!--日志名称，如果没有File 属性，那么只会使用FileNamePattern的文件路径规则                                     如果同时有&lt;File&gt;和&lt;FileNamePattern&gt;，那么当天日志是&lt;File&gt;，明天会自动把今天                                     的日志改名为今天的日期。即，&lt;File&gt; 的日志都是当天的。                                 --&gt;                                 &lt;File&gt;${logback.logdir}/info.${logback.appname}.log&lt;/File&gt;                                 &lt;!--滚动策略，按照时间滚动 TimeBasedRollingPolicy--&gt;                                 &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;                                     &lt;!--文件路径,定义了日志的切分方式——把每一天的日志归档到一个文件中,以防止日志填满整个磁盘空间--&gt;                                     &lt;FileNamePattern&gt;${logback.logdir}/info.${logback.appname}.%d{yyyy-MM-dd}.log&lt;/FileNamePattern&gt;                                     &lt;!--只保留最近90天的日志--&gt;                                     &lt;maxHistory&gt;90&lt;/maxHistory&gt;                                     &lt;!--用来指定日志文件的上限大小，那么到了这个值，就会删除旧的日志--&gt;                                     &lt;!--&lt;totalSizeCap&gt;1GB&lt;/totalSizeCap&gt;--&gt;                                 &lt;/rollingPolicy&gt;                                 &lt;!--日志输出编码格式化--&gt;                                 &lt;encoder&gt;                                     &lt;charset&gt;UTF-8&lt;/charset&gt;                                     &lt;pattern&gt;%d [%thread] %-5level %logger{36} %line - %msg%n&lt;/pattern&gt;                                 &lt;/encoder&gt;                             &lt;/appender&gt;                             &lt;appender name=&quot;fileErrorLog&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;                                 &lt;!--如果只是想要 Error 级别的日志，那么需要过滤一下，默认是 info 级别的，ThresholdFilter--&gt;                                 &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;                                     &lt;level&gt;Error&lt;/level&gt;                                 &lt;/filter&gt;                                 &lt;!--日志名称，如果没有File 属性，那么只会使用FileNamePattern的文件路径规则                                     如果同时有&lt;File&gt;和&lt;FileNamePattern&gt;，那么当天日志是&lt;File&gt;，明天会自动把今天                                     的日志改名为今天的日期。即，&lt;File&gt; 的日志都是当天的。                                 --&gt;                                 &lt;File&gt;${logback.logdir}/error.${logback.appname}.log&lt;/File&gt;                                 &lt;!--滚动策略，按照时间滚动 TimeBasedRollingPolicy--&gt;                                 &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;                                     &lt;!--文件路径,定义了日志的切分方式——把每一天的日志归档到一个文件中,以防止日志填满整个磁盘空间--&gt;                                     &lt;FileNamePattern&gt;${logback.logdir}/error.${logback.appname}.%d{yyyy-MM-dd}.log&lt;/FileNamePattern&gt;                                     &lt;!--只保留最近90天的日志--&gt;                                     &lt;maxHistory&gt;90&lt;/maxHistory&gt;                                     &lt;!--用来指定日志文件的上限大小，那么到了这个值，就会删除旧的日志--&gt;                                     &lt;!--&lt;totalSizeCap&gt;1GB&lt;/totalSizeCap&gt;--&gt;                                 &lt;/rollingPolicy&gt;                                 &lt;!--日志输出编码格式化--&gt;                                 &lt;encoder&gt;                                     &lt;charset&gt;UTF-8&lt;/charset&gt;                                     &lt;pattern&gt;%d [%thread] %-5level %logger{36} %line - %msg%n&lt;/pattern&gt;                                 &lt;/encoder&gt;                             &lt;/appender&gt;                             如果同时有&lt;File&gt;和&lt;FileNamePattern&gt;，根据日期分割日志，代码注释写的很清楚了。                              如果要区分 Info 和 Error 级别的日志，那么需要使用过滤规则的策略，代码注释写的很清楚了                         子节点五&lt;loger&gt;                             &lt;loger&gt;用来设置某一个包或者具体的某一个类的日志打印级别、以及指定&lt;appender&gt;。                             &lt;loger&gt;仅有一个name属性，一个可选的level和一个可选的addtivity属性。                             name:用来指定受此loger约束的某一个包或者具体的某一个类。                             level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF，                             还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。如果未设置此属性，那么当前loger将会继承上级的级别。                             addtivity:是否向上级loger传递打印信息。默认是true。                             第一种：带有loger的配置，不指定级别，不指定appender                                     logback-spring.xml增加 loger 配置如下：                                     &lt;logger name=&quot;com.dudu.controller&quot;/&gt;                                     1                                     &lt;logger name=&quot;com.dudu.controller&quot; /&gt;将控制controller包下的所有类的日志的打印，                                     但是并没用设置打印级别，所以继承他的上级的日志级别“info”；                                      没有设置addtivity，默认为true，将此loger的打印信息向上级传递；                                      没有设置appender，此loger本身不打印任何信息。                                      &lt;root level=&quot;info&quot;&gt;将root的打印级别设置为“info”，指定了名字为“console”的appender。                                     当执行com.dudu.controller.LearnController类的login方法时，LearnController 在包com.dudu.controller中，                                     所以首先执行&lt;logger name=&quot;com.dudu.controller&quot;/&gt;，将级别为“info”及大于“info”的日志信息传递给root，本身并不打印；                                      root接到下级传递的信息，交给已经配置好的名为“console”的appender处理，“console” appender 将信息打印到控制台                             第二种：带有多个loger的配置，指定级别，指定appender，                                     logback-spring.xml增加 loger 配置如下：                                     &lt;configuration&gt;                                         ...                                         &lt;!--logback.LogbackDemo：类的全路径 --&gt;                                         &lt;logger name=&quot;com.dudu.controller.LearnController&quot; level=&quot;WARN&quot; additivity=&quot;false&quot;&gt;                                             &lt;appender-ref ref=&quot;console&quot;/&gt;                                         &lt;/logger&gt;                                     &lt;/configuration&gt;                                     控制com.dudu.controller.LearnController类的日志打印，打印级别为“WARN”;                                      additivity属性为false，表示此loger的打印信息不再向上级传递;                                      指定了名字为“console”的appender;                                     这时候执行com.dudu.controller.LearnController类的login方法时，                                     先执行&lt;logger name=&quot;com.dudu.controller.LearnController&quot; level=&quot;WARN&quot; additivity=&quot;false&quot;&gt;,                                     将级别为“WARN”及大于“WARN”的日志信息交给此loger指定的名为“console”的appender处理，                                     在控制台中打出日志，不再向上级root传递打印信息                                     当然如果你把additivity=&quot;false&quot;改成additivity=&quot;true&quot;的话，就会打印两次，                                     因为打印信息向上级传递，logger本身打印一次，root接到后又打印一次。                                     &lt;configuration&gt;                                         ...                                         &lt;logger name=&quot;com.example.demo.controller&quot; level=&quot;WARN&quot; additivity=&quot;false&quot;&gt;                                            &lt;appender-ref ref=&quot;consoleLog&quot;/&gt;                                         &lt;/logger&gt;                                         &lt;logger name=&quot;com.example.demo.controller&quot;/&gt;                                         &lt;logger name=&quot;com.example.demo&quot;/&gt;                                     &lt;/configuration&gt;                                     范围有重叠的话，范围小的，有效。                 多环境日志输出：                      &lt;configuration&gt;                         ...                         &lt;!-- 测试环境+开发环境. 多个使用逗号隔开. --&gt;                         &lt;springProfile name=&quot;test,dev&quot;&gt;                             &lt;logger name=&quot;com.example.demo.controller&quot; level=&quot;DEBUG&quot; additivity=&quot;false&quot;&gt;                                 &lt;appender-ref ref=&quot;consoleLog&quot;/&gt;                             &lt;/logger&gt;                         &lt;/springProfile&gt;                         &lt;!-- 生产环境. --&gt;                         &lt;springProfile name=&quot;prod&quot;&gt;                             &lt;logger name=&quot;com.example.demo.controller&quot; level=&quot;INFO&quot; additivity=&quot;false&quot;&gt;                                 &lt;appender-ref ref=&quot;consoleLog&quot;/&gt;                             &lt;/logger&gt;                         &lt;/springProfile&gt;                     &lt;/configuration&gt;                 application.yml增加环境选择的配置active: dev                     server:                       port: 9010                     spring:                       profiles:                         active: dev                       datasource:                         url: jdbc:mysql://localhost:3306/test?characterEncoding=utf8                         username: root                         password: root                     mybatis:                         type-aliases-package: org.larry.springboot.entity                         mapper-locations: classpath:mapper/**/*.xml                         check-config-location: true                 active: 【test、dev、prod】，根据 active 的环境，自动采用上面配置的springProfile的 logger 日志                 使用application.yml 自定义日志路径（application.yml）                 application.yml增加日志相关自定义配置：                    logback:                       logdir: /Users/inke/dev/log/tomcat/sell                       appname: sell                 在logback-spring.xml                    &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;                         &lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt;                             &lt;!--application.yml 传递参数，不能使用logback 自带的&lt;property&gt;标签 --&gt;                             &lt;springProperty scope=&quot;context&quot; name=&quot;appname&quot; source=&quot;logback.appname&quot;/&gt;                             &lt;springProperty scope=&quot;context&quot; name=&quot;logdir&quot; source=&quot;logback.logdir&quot;/&gt;                             &lt;contextName&gt;${appname}&lt;/contextName&gt;                             &lt;!--输出到控制台 ConsoleAppender--&gt;                             &lt;appender name=&quot;consoleLog&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;                                 &lt;!--展示格式 layout--&gt;                                 &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt;                                     &lt;pattern&gt;                                         &lt;pattern&gt;%d{HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36} - %msg%n&lt;/pattern&gt;                                     &lt;/pattern&gt;                                 &lt;/layout&gt;                             &lt;/appender&gt;                 为了更全面一点总结日志配置，除了自己总结，也百度摘录归纳糅合进许多好的讲解点，可能有点多和杂，但绝对是必要的！！！</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;springboot ---   日志使用

首先，假设我们要开发一个大型系统；
  那么关于日志：
 1、System.out.println(&amp;quot;&amp;quot;)；将关键数据打印在控制台；去掉？写在一个文件？
 2、框架来记录系统的一些运行时信息；
      
    
    </summary>
    
      <category term="springboot" scheme="https://liuhusen.com/categories/springboot/"/>
    
    
      <category term="微服务" scheme="https://liuhusen.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="springboot" scheme="https://liuhusen.com/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>redis的aof，dump等</title>
    <link href="https://liuhusen.com/2019/01/18/redis%E7%9A%84aof%EF%BC%8Cdump%E7%AD%89/"/>
    <id>https://liuhusen.com/2019/01/18/redis的aof，dump等/</id>
    <published>2019-01-18T07:01:30.000Z</published>
    <updated>2019-04-06T12:29:32.844Z</updated>
    
    <content type="html"><![CDATA[<pre><code>Redis自动备份有两种方式，第一种是通过dump.rdb文件实现备份，另外一种使用aof文件实现自动备份。Dump.rdb备份Redis中默认使用dump.rdb文件实现备份，如果aof备份没有打开，那么启动redis时，会默认从dump.rbd文件中读取原始数据.如何配置dump.rdb备份，在redis.conf文件中有命令：save 900 1save 300 10save 60 10000123它代表的意思是dump备份的条件，在900s内有一个key发生改变/300s中有10个key发生改变/60s内有10000个key发生改变时，redis将将当前数据库快照到dump.rdb文件中。也可以执行命令来实现手动备份SAVE1SAVE命令表示使用主进程将当前数据库快照到dump文件BGSAVE1BGSAVE命令表示，主进程会fork一个子进程来进行快照备份。两者的不同是，前者会阻塞主进程，而后者不会，所以一般使用BGSAVE进行手动备份。redis快照到dump文件时，会先生成一个temp.rdb文件，然后重命名为dump.rdb文件替换原来文件实现备份。redis.conf中的dbfilename dump.rdb  //修改dump文件名称dir ./    //修改dump文件的文件路径123aof文件备份redis默认关闭了aof文件备份，redis.conf文件中找到appendonly no1把no改为yesappendfilename appendonly.aof1可以修改默认的aof文件名appendfsync everysec1这里默认的everysec会在安全和效率之间权衡，redis默认会每隔1s就调用fsync函数，将缓冲区的数据写到磁盘里面，但是当fsync函数执行时间超过1s时，redis会适当延迟写操作。当appendfsync设置为always时，redis会针对每一个写操作都刷新到磁盘，这样虽然安全，但是性能会有所降低。当设置为no时，redis不会主动对数据进行备份，这时什么时候刷新备份，就依赖于操作系统的设置了。Aof bgrewriteaof操作aof文件备份，会备份数据库的历史记录，以及相应执行过的指令，相当于一个log文件，在恢复数据库的时候会回滚执行命令，同时恢复数据。这样带来的一个问题就是，aof文件会越来越大，如果有一百条指令，最后一条指令恢复的最终数据库，那么前99条指令及相应的数据也会存在在aof文件中。如何解决的这个问题呢？可以执行命令：bgrewriteaof1就会把当前数据库刷新到aof文件中，此时aof文件中将只会保存当前数据库的数据，所以如果数据库被入侵清空，请谨慎执行这个命令，因为它会数据库上的历史数据消失。redis也会自动调用bgwriteaof操作：auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb12这里的设置针对redis自动进行rewriteaof操作。percentage是指，当redis当前的aof文件大小相对于上一次进行rewriteaof操作时的大小增长率大于100%时，就会进行rewrite，这里可以自己设置。但是，当增长率大于了100%，实际上aof文件其实很小，这样rewrite就没有必要了，所以，还需要设置一个min-size，当redis的增长率大于100%，并且min-size的大于64mb时，就会执行rewriteaof操作。如果想关闭rewriteaof操作，可以将percentage设置为0。redis会在以下三个时候进行rewrite操作Redis接收到客户端发送的bgrewriteaof命令Redis aof文件增长率和增长大小达到auto-aof-rewriteRedis接收到客户端发送的”CONFIG SET appendonly yes”命令aof与dump备份不同aof文件备份与dump文件备份不同。dump文件的编码格式和存储格式与数据库一致，而且dump文件中备份的是数据库的当前快照，意思就是，不管数据之前什么样，只要BGSAVE了，dump文件就会刷新成当前数据库数据。当redis重启时，会按照以下优先级进行启动：如果只配置AOF,重启时加载AOF文件恢复数据；如果同时 配置了RBD和AOF,启动是只加载AOF文件恢复数据;如果只配置RBD,启动时将加载dump文件恢复数据。注意：只要配置了aof，但是没有aof文件，这个时候启动的数据库会是空的在linux环境运行Redis时，如果系统的内存比较小，这个时候自动备份会有可能失败，需要修改系统的vm.overcommit_memory 参数，这个参数是干什么的呢，它有三个选值，是linux系统的内存分配策略：0， 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。2， 表示内核允许分配超过所有物理内存和交换空间总和的内存Redis官方的说明是，建议将vm.overcommit_memory的值修改为1，可以用下面几种方式进行修改：（1）编辑/etc/sysctl.conf ，改vm.overcommit_memory=1，然后sysctl -p 使配置文件生效（2）sysctl vm.overcommit_memory=1（3）echo 1 &gt; /proc/sys/vm/overcommit_memory</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;Redis自动备份有两种方式，第一种是通过dump.rdb文件实现备份，另外一种使用aof文件实现自动备份。

Dump.rdb备份
Redis中默认使用dump.rdb文件实现备份，如果aof备份没有打开，那么启动redis时，会默认从dump.rbd文件
      
    
    </summary>
    
      <category term="redis" scheme="https://liuhusen.com/categories/redis/"/>
    
    
      <category term="缓存数据库" scheme="https://liuhusen.com/tags/%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="redis" scheme="https://liuhusen.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>springboot整合Spring Data JPA的遇到的问题</title>
    <link href="https://liuhusen.com/2019/01/10/springboot%E6%95%B4%E5%90%88Spring%20Data%20JPA%E7%9A%84%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>https://liuhusen.com/2019/01/10/springboot整合Spring Data JPA的遇到的问题/</id>
    <published>2019-01-10T05:01:30.000Z</published>
    <updated>2019-04-06T09:31:57.548Z</updated>
    
    <content type="html"><![CDATA[<pre><code>声明： 以下问题仅针对使用jdk9的情况springboot整合Spring Data JPA的遇到的问题，报错如下：     Caused by: java.lang.ClassNotFoundException: javax.xml.bind.JAXBException             at java.base/jdk.internal.loader......................................             ............................................................此处省略 原因：jdk9缺少相应的jar 解决方案：手动导入对应的maven坐标，如下     &lt;!--jdk9需要导入如下坐标--&gt;     &lt;dependency&gt;         &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt;         &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt;         &lt;version&gt;2.3.0&lt;/version&gt;     &lt;/dependency&gt;</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;声明： 以下问题仅针对使用jdk9的情况


springboot整合Spring Data JPA的遇到的问题，报错如下：

     Caused by: java.lang.ClassNotFoundException: javax.xml.bind.
      
    
    </summary>
    
      <category term="springboot" scheme="https://liuhusen.com/categories/springboot/"/>
    
    
      <category term="微服务" scheme="https://liuhusen.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="springboot" scheme="https://liuhusen.com/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>springboot之创建后mysql连接报错</title>
    <link href="https://liuhusen.com/2019/01/10/springboot%E4%B9%8B%E5%88%9B%E5%BB%BA%E5%90%8Emysql%E8%BF%9E%E6%8E%A5%E6%8A%A5%E9%94%99/"/>
    <id>https://liuhusen.com/2019/01/10/springboot之创建后mysql连接报错/</id>
    <published>2019-01-10T05:01:30.000Z</published>
    <updated>2019-04-06T08:08:32.463Z</updated>
    
    <content type="html"><![CDATA[<pre><code>给springboot项目配置mysql出错，如下：    mysql 错误：java.sql.SQLException: Unknown system variable &apos;language&apos;            at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:965) ~[mysql-connector-java-5.1.46.jar:5.1.46]            at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3976) ~[mysql-connector-java-5.1.46.jar:5.1.46]            at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3912) ~[mysql-connector-java-5.1.46.jar:5.1.46]            ......................解决方法如下：            因为数据库的pom配置或者引用的驱动jar包版本过高，而导致无法发现系统的变量            1. 在mysql数据库执行  select version() ， 查看mysql版本            2. 将查询到的版本与当前项目pom文件里引用版本对比。看是否版本一致。如果不一致，调整为一致的版本即可</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;给springboot项目配置mysql出错，如下：

    mysql 错误：java.sql.SQLException: Unknown system variable &amp;apos;language&amp;apos;
            at com.m
      
    
    </summary>
    
      <category term="springboot" scheme="https://liuhusen.com/categories/springboot/"/>
    
    
      <category term="微服务" scheme="https://liuhusen.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="springboot" scheme="https://liuhusen.com/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>springboot之创建后访问不到controller</title>
    <link href="https://liuhusen.com/2019/01/08/springboot%E4%B9%8B%E5%88%9B%E5%BB%BA%E5%90%8E%E8%AE%BF%E9%97%AE%E4%B8%8D%E5%88%B0controller/"/>
    <id>https://liuhusen.com/2019/01/08/springboot之创建后访问不到controller/</id>
    <published>2019-01-08T05:01:30.000Z</published>
    <updated>2019-04-04T08:41:30.871Z</updated>
    
    <content type="html"><![CDATA[<pre><code>SpringBoot有个Application入口能够让你从这里启动程序，但是新手往往容易出现一个问题，有了Application，但是程序就是一直有问题。比如：程序正常启动且没有报错，但是访问不到Controller这是因为SpringBoot大部分情况下是基于注解扫描。@SpringBootApplication自动会扫描大部分的注解，所以官方建议Application应该放在所有包的根包那里。这样@SpringBootApplication扫描的时候，才会把下属所有的子子孙孙包中的controller也好、dao也好，给扫出来。所以尼，如果访问不到，去检查一下你的Application放在那里了！！！</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;SpringBoot有个Application入口能够让你从这里启动程序，但是新手往往容易出现一个问题，有了Application，但是程序就是一直有问题。

比如：程序正常启动且没有报错，但是访问不到Controller

这是因为SpringBoot大部
      
    
    </summary>
    
      <category term="springboot" scheme="https://liuhusen.com/categories/springboot/"/>
    
    
      <category term="微服务" scheme="https://liuhusen.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="springboot" scheme="https://liuhusen.com/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>mysql存储过程和oracle存储过程对比</title>
    <link href="https://liuhusen.com/2018/12/30/mysql%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E5%92%8Coracle%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E5%AF%B9%E6%AF%94/"/>
    <id>https://liuhusen.com/2018/12/30/mysql存储过程和oracle存储过程对比/</id>
    <published>2018-12-29T18:01:30.000Z</published>
    <updated>2019-04-02T03:33:26.078Z</updated>
    
    <content type="html"><![CDATA[<pre><code>区别如下：       1      创建存储过程语句不同：           ORACLE：  create or replace procedure P_ADD_FAC(id_fac_cd  IN ES_FAC_UNIT.FAC_CD%TYPE) is               MYSQL：   DROP PROCEDURE IF EXISTS `SD_USER_P_ADD_USR`;create procedure P_ADD_FAC(id_fac_cd  varchar(100))                注释：1.在创建存储过程时如果存在同名的存储过程,会删除老的存储过程.                      oracle使用create or replace.                     mysql使用先删除老的存储过程,然后再创建新的存储过程.                  2. oracle 存储过程可以定义在package中,也可以定义在Procedures中. 如果定义在包中,                     一个包中可以包含多个存储过程和方法.如果定义在Procedures中,存储过程中不可以定义多个存储过程.                      Mysql  存储过程中不可以定义多个存储过程.                   3. oracle中字符串类型可以使用varchar2.                       Mysql 需要使用varchar                  4. Oracle中参数varchar长度不是必须的,                     Mysql中参数varchar长度是必须的, 比如varchar(100)       2    创建函数语句不同：            ORACLE： CREATE OR REPLACEFUNCTION F_ROLE_FACS_GRP(                       ii_role_int_key IN SD_ROLE.ROLE_INT_KEY%TYPE                      ) RETURN VARCHAR2               MYSQL： DROP FUNCTION IF EXISTS `SD_ROLE_F_ROLE_FACS_GRP`;                      CREATE  FUNCTION `SD_ROLE_F_ROLE_FACS_GRP`(                       ii_role_int_key INTEGER(10)                      ) RETURNS varchar(1000)               注释：        1.在创建函数时如果存在同名的函数,会删除老的函数.                          oracle使用create or replace.                        mysql使用先删除老的函数,然后再创建新的函数.                      2. oracle 函数可以定义在package中,也可以定义在Functions中. 如果定义在包中,一个包中可以包含多个存储过程和函数.如果定义在Functions中,每个函数只能定义一个函数.                         Mysql  Functions不可以定义多个函数.                       3.  oracle返回值用return.                           Mysql返回值用returns.       3    传入参数写法不同：           ORACLE：procedure P_ADD_FAC(                   id_fac_cd  IN ES_FAC_UNIT.FAC_CD%TYPE)               MYSQL： create procedure P_ADD_FAC(                   (in) id_fac_cd  varchar(100))              注释：    1. oracle存储过程参数可以定义为表的字段类型.                     Mysql存储过程不支持这种定义方法.需要定义变量的实际类型和长度.                  2. oracle 参数类型in/out/inout写在参数名后面.                      Mysql  参数类型in/out/inout写在参数名前面.                  3. oracle 参数类型in/out/inout 都必须写.                     Mysql  参数类型如果是in,则可以省略. 如果是out或inout则不能省略.                  注意: mysql中指定参数为IN, OUT, 或INOUT 只对PROCEDURE是合法的。（FUNCTION参数总是被认为是IN参数） RETURNS字句只能对FUNCTION做指定，对函数而言这是强制的。它用来指定函数的返回类型，而且函数体必须包含一个RETURN value语句。                    function func_name(                             gw_id  in(out)  varchar2 )    create function func_name(                         gw_id varchar（100))      4    包的声明方式：           ORACLE：create or replace package/package body package name               MYSQL： 拆分成多个存储过程或函数               注释： oracle可以创建包,包中可以包含多个存储过程和方法.                   mysql没有没有包这个概念,可以分别创建存储过程和方法. 每个存储过程或方法都需要放在一个文件中.                   例1: 方法命名                   oracle 中SD_FACILITY_PKG.F_SEARCH_FAC                   to mysql SD_FACILITY_F_SEARCH_FAC                   例2: 过程命名                  oracle 中SD_FACILITY_PKG.P_ADD_FAC                  to mysql SD_FACILITY_P_ADD_FAC       5    存储过程返回语句不一样：          ORACLE：return;              MYSQL： LEAVE proc; (proc 代表最外层的begin end)              注释：  oracle存储过程和方法都可以使用return退出当前过程和方法.                   Mysql存储过程中只能使用leave退出当前存储过程.不可以使用return.                   Mysql方法可以使用return退出当前方法.       6    存储过程异常处理不一样：          ORACLE：EXCEPTION                  WHEN OTHERS THEN                  ROLLBACK ;                  ov_rtn_msg := c_sp_name||&apos;(&apos;|| li_debug_pos ||&apos;):&apos;||                      TO_CHAR(SQLCODE)||&apos;: &apos;||SUBSTR(SQLERRM,1,100);              MYSQL：    DECLARE EXIT HANDLER FOR  SQLEXCEPTION                    BEGIN                      ROLLBACK ;                      set ov_rtn_msg = concat(c_sp_name,&apos;(&apos;, li_debug_pos ,&apos;):&apos;,                          TO_CHAR(SQLCODE),&apos;: &apos;,SUBSTR(SQLERRM,1,100));                   END;              注释： oracle : 内部异常不需要定义,在存储过程或函数末尾写上EXCEPTION后,后面的部分即为异常处理的部分.                            oracle可以定义自定义异常,自定义异常需要使用raise关键字抛出异常后,才可以在EXCEPTION中捕获.                  mysql: mysql内部异常也需要先定义,在定义的同时也需要实现异常的功能.                             目前mysql不支持自定义异常.       7    过程和函数的声明变量的位置不同：            ORACLE：声明变量在begin…end体之前              MYSQL：    声明变量在begin...end体内，begin之后其他任何内容之前    　      8    NO_DATA_FOUND异常处理：          ORACLE：EXCEPTION                  WHEN NO_DATA_FOUND THEN                      oi_rtn_cd := 1;                      ov_rtn_msg := SD_COMMON.P_GET_MSG(&apos;DP-CBM-01100a-016&apos;,                                                       li_sub_rtn_cd,                                                       lv_sub_rtn_msg);              MYSQL：    使用FOUND_ROWS()代替NO_DATA_FOUND.           注释：    oracle中:                           NO_DATA_FOUND是游标的一个属性.                           当select没有查到数据就会出现 no data found 的异常，程序不会向下执行.                  Mysql:                           没有NO_DATA_FOUND这个属性.但可是使用FOUND_ROWS()方法得到select语句查询出来的数据.                          如果FOUND_ROWS()得到的值为0,就进入异常处理逻辑.       9    在存储过程中调用存储过程方式的不同：          ORACLE：Procedure_Name(参数);              MYSQL：    Call Procedure_Name(参数);              注释：MYSQL存储过程调用存储过程，需要使用Call pro_name(参数).                  Oracle调用存储过程直接写存储过程名就可以了.       10    抛异常的方式不同：          ORACLE：RAISE Exception_Name;          MYSQL：    待续。。。。。。。。            </code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;区别如下： 

      1      创建存储过程语句不同：

           ORACLE：  create or replace procedure P_ADD_FAC(id_fac_cd  IN ES_FAC_UNIT.FAC_CD%TYPE
      
    
    </summary>
    
      <category term="数据库" scheme="https://liuhusen.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="存储过程" scheme="https://liuhusen.com/tags/%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B/"/>
    
      <category term="数据库相关操作" scheme="https://liuhusen.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>oraclel存储过程------学习笔记</title>
    <link href="https://liuhusen.com/2018/12/28/oraclel%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B------%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>https://liuhusen.com/2018/12/28/oraclel存储过程------学习笔记/</id>
    <published>2018-12-28T07:22:52.000Z</published>
    <updated>2019-04-02T06:24:26.740Z</updated>
    
    <content type="html"><![CDATA[<pre><code>Oracle存储过程实例如下：       过程： 就是高级程序设计语言中的模块的概念，将一些内部联系的命令组成一个个过程，通过             参数在过程之间传递数据是模块化设计思想的重要内容。      存储过程： 1.是预编译过的，并且经优化后存储于SQL内存中，使用时无需再次编译，提高了工作效率                 2.存储过程的代码直接存放于数据库中，一般由客户端直接通过存储过程的名字进行调用，                   减少了网络流量，加快了系统执行速度，例如在进行百万以上的大批量数据查询时，使                   用存储过程分页要比其他方式分页快的多                 3.使用存储过程可以减少SQL注入式攻击，提高系统的安全性，执行存储过程的用户要具有一定                   的权限才能使用存储过程，没有数据操作权限的用户只能在其控制下间接的存取数据                 4.在同时进行主，从表及多表之间的数据维护及有效性验证时，使用存储过程比较方便，而且                   可以有效利用SQL中的事务处理的机制                 5.使用存储过程，可以实现存储过程设计和编码工作分开进行，只要将存储过程名、参数、及返回信息                   告诉编码人员即可；                 6.但使用存储过程封装业务逻辑将限制应用程序的可移植性；另外，如果更改存储过程的参数或者其返回                   的数据及类型的话，需要修改应用程序的相关代码，比较繁琐。      过程的语法结构：          完整的过程结构如下：                   create or replace procedure 过程名 as                   声明语句段；                   begin                   执行语句段；                   exception                   异常处理语句段；                   end；          过程是有名称的程序块，as关键词代替了无名块的 declare；          创建过程实例：              * 创建名为 stu_proc的过程，create是创建过程的标识符，replace表示若同名过程存在将覆盖原过程，                该过程定义了一个变量，其类型和student数据表中的sname字段类型相同，都是字符型，将数据表中                的sno字段为 1 的sname字段内容送入变量中，然后输出结果。                ------学生表 student                  create table student (                  sno number(6),                  sname varchar2(25),                  pno number(6) primary key                  );                  select * from student;                  --create sequence student_seq;                ------存储过程                  create or replace procedure stu_proce as                   p_name varchar2(25);                  begin                    select sanme into p_name from student where sno=1;                    dbms_output.put_line(p_name);                  end;                --调用存储过程                  call stu_proc();</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;Oracle存储过程实例如下： 

      过程： 就是高级程序设计语言中的模块的概念，将一些内部联系的命令组成一个个过程，通过
             参数在过程之间传递数据是模块化设计思想的重要内容。

      存储过程： 1.是预编译过的，并
      
    
    </summary>
    
      <category term="数据库" scheme="https://liuhusen.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="存储过程" scheme="https://liuhusen.com/tags/%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B/"/>
    
      <category term="数据库相关操作" scheme="https://liuhusen.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>mysql存储过程------其他相关操作</title>
    <link href="https://liuhusen.com/2018/12/09/mysql%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B------%E5%85%B6%E4%BB%96%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C/"/>
    <id>https://liuhusen.com/2018/12/09/mysql存储过程------其他相关操作/</id>
    <published>2018-12-09T02:03:30.000Z</published>
    <updated>2019-04-02T03:02:25.141Z</updated>
    
    <content type="html"><![CDATA[<pre><code>操作如下：           CREATE TABLE `tstudent4` (            `id` int(15) NOT NULL,            `Sname` varchar(32) DEFAULT NULL,            `sex` char(1) DEFAULT NULL,            `cardID` int(12) DEFAULT NULL,            `Birthday` date DEFAULT NULL,            `Email` varchar(40) DEFAULT NULL,            `Class` varchar(20) DEFAULT NULL,            `enterTime` datetime DEFAULT NULL,            `cmos_modify_time` datetime(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3) ON UPDATE CURRENT_TIMESTAMP(3),            PRIMARY KEY (`id`),            KEY `pri_stuid` (`id`),            KEY `idx_cmos_modify_time` (`cmos_modify_time`)          ) ENGINE=InnoDB DEFAULT CHARSET=utf8          ----------------------------------------------------------------------          DELIMITER $$          CREATE PROCEDURE `testStudent`( IN iCount INT)          BEGIN                  DECLARE i INT;                  DECLARE    inum INT;                  DECLARE    iid INT;                  start transaction;                  SET i =1;                  SELECT COUNT(0) INTO inum FROM tstudent4;                  IF inum &gt; 1                      THEN SELECT MAX(id) INTO inum FROM tstudent4;                  END IF;                  WHILE i &lt;= iCount DO                  INSERT tstudent4 VALUES (                      inum+i,                      CONCAT(&apos;李长青&apos;,inum+i),                      IF(CEIL(RAND()*10)%2=0,&apos;男&apos;,&apos;女&apos;),                      CEIL(RAND()*100000000),                      CONCAT(CONVERT(CEIL(RAND()*10)+1980,CHAR(4)),&apos;-&apos;,LPAD(CONVERT(CEIL(RAND()*12),                      CHAR(2)),2,&apos;0&apos;),&apos;-&apos;,LPAD(CONVERT(CEIL(RAND()*28),CHAR(2)),2,&apos;0&apos;)),                      CONCAT(CONCAT(&apos;lichangqing&apos;,inum+i),&apos;@hotmail.com&apos;),                      CASE CEIL(RAND()*3) WHEN 1 THEN &apos;网络与网站开发&apos; WHEN 2 THEN &apos;计算机科学技术&apos; ELSE &apos;性能巧匠训练营&apos; END,                      NOW(),CURRENT_TIMESTAMP(3));                  SET i = i + 1;                  END WHILE;                  commit;                  SET i =CEIL(RAND()*iCount);                  SELECT id INTO iid FROM tstudent4 ORDER BY RAND() LIMIT 1;                   UPDATE tstudent4 SET sname=CONCAT(&apos;张芳敏&apos;,id), cardID=CEIL(RAND()*100000000) WHERE id between iid and  iid+i;                  SET i =CEIL(RAND()*iCount);                  SELECT id INTO iid FROM tstudent4 ORDER BY RAND() LIMIT 1;                   delete from tstudent4 WHERE id between iid and  iid+i;              END$$          DELIMITER ;          ----------------------------清理2小时前的binlog日志--------------------------------------------、          DELIMITER $$          CREATE  PROCEDURE `clearlog`()          BEGIN                  PURGE MASTER LOGS BEFORE DATE_SUB(CURRENT_TIME, INTERVAL 2 HOUR);          END$$          DELIMITER ;          -----------------------------mysql相关设置开关--------------------------------------          SHOW VARIABLES LIKE &apos;event_scheduler&apos;          SET GLOBAL event_scheduler = 1;          SHOW VARIABLES LIKE &apos;autocommit&apos;          set session autocommit = 0;          --设置safe update模式          SHOW VARIABLES LIKE &apos;SQL_SAFE_UPDATES&apos;;          set SQL_SAFE_UPDATES = 1;          ----------------------------创建事务--------------------------------------------          CREATE  EVENT `example_event2`           ON SCHEDULE EVERY 10 SECOND STARTS CURRENT_TIMESTAMP           ON COMPLETION NOT PRESERVE ENABLE           DO call testStudent(100);          -------------------binlog相关--------------------------------------------------------          show global variables like &apos;gtid_%&apos;;     //查询gtid信息：          show global variables like &apos;server_uuid&apos;;  //查看机器uuid：          中断存储过程或者事务          show processlist；          kill  id          show binlog events in &apos;mysql-bin.000002&apos;;   //查看指定binlog文件的内容          show binary logs;  //获取binlog列表          show  master logs;  //查询日志          --------------------------------------DDL操作-----------------------------------------------          CREATE TABLE `testtab` (            `id` int(15) NOT NULL,            `Sname` varchar(10) DEFAULT NULL,            `sex` char(1) DEFAULT NULL,            `cardID` int(12) DEFAULT NULL,            `Birthday` date DEFAULT NULL,            `Email` varchar(40) DEFAULT NULL            ) ENGINE=InnoDB DEFAULT CHARSET=utf8;          插入列：          ALTER TABLE testtab ADD testdate DATETIME DEFAULT NOW();             更新列类型：          ALTER TABLE testtab MODIFY  testdate varchar(12) DEFAULT NULL COMMENT &apos;测试列更新&apos;;          更新列名：          ALTER TABLE testtab change  testdate changecol int(12);          删除列：          ALTER TABLE testtab DROP changecol;          创建主键：          alter table testtab add primary key(id);          全文索引：          CREATE  FULLTEXT INDEX IDX_KSD  ON  testtab (email);          普通索引：          CREATE   INDEX IDX_NAME  ON  testtab (sname);          唯一索引：          CREATE UNIQUE  INDEX IDX_STUNAME  ON  testtab (sname);          组合索引：          CREATE INDEX MultiIdx   ON testtab (id,sname);          主键索引：          CREATE   INDEX IDX_ID  ON  testtab (id);          BTREE索引：          CREATE   INDEX IDX_cardid USING BTREE  ON  testtab (cardID);          删除索引：          DROP INDEX  IDX_KSD  ON testtab ;          DROP INDEX  IDX_NAME  ON testtab ;          DROP INDEX  IDX_STUNAME  ON testtab ;          DROP INDEX  MultiIdx  ON testtab ;          DROP INDEX  IDX_ID  ON testtab ;          DROP INDEX  IDX_cardid  ON testtab ;          删除主键：          alter table testtab drop primary key;          重命名表：          rename table testtab to tsrenmtabl;          删除表：          DROP TABLE tsrenmtabl;</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;操作如下： 
          CREATE TABLE `tstudent4` (
            `id` int(15) NOT NULL,
            `Sname` varchar(32) DEFAULT NULL,
    
      
    
    </summary>
    
      <category term="数据库" scheme="https://liuhusen.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="存储过程" scheme="https://liuhusen.com/tags/%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B/"/>
    
      <category term="数据库相关操作" scheme="https://liuhusen.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>mysql存储过程------批量建表删表</title>
    <link href="https://liuhusen.com/2018/12/08/mysql%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B------%E6%89%B9%E9%87%8F%E5%BB%BA%E8%A1%A8%E5%88%A0%E8%A1%A8/"/>
    <id>https://liuhusen.com/2018/12/08/mysql存储过程------批量建表删表/</id>
    <published>2018-12-08T05:01:30.000Z</published>
    <updated>2019-04-02T03:00:19.461Z</updated>
    
    <content type="html"><![CDATA[<pre><code>操作如下：       CREATE TABLE `tstudent4` (        `studentID` int(15) NOT NULL,        `Sname` varchar(64) DEFAULT NULL,        `sex` char(1) DEFAULT NULL,        `cardID` varchar(20) DEFAULT NULL,        `Birthday` date DEFAULT NULL,        `Email` varchar(40) DEFAULT NULL,        `Class` varchar(20) DEFAULT NULL,        `enterTime` datetime DEFAULT NULL,        `remarks` mediumtext,        `cmos_modify_time` datetime(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3) ON UPDATE CURRENT_TIMESTAMP(3),        PRIMARY KEY (`studentID`),        KEY `pri_stuid` (`studentID`),        KEY `idx_cmos_modify_time` (`cmos_modify_time`)      ) ENGINE=InnoDB DEFAULT CHARSET=utf8      ----------------------------------------------------------------------      DELIMITER $$      CREATE PROCEDURE `addStudent4`( IN iCount INT)      BEGIN              DECLARE i INT;              DECLARE    inum INT;              SET i =1;              SELECT COUNT(0) INTO inum FROM tstudent4;              IF inum &gt; 1                  THEN SELECT MAX(studentID) INTO inum FROM tstudent4;              END IF;              start transaction;              WHILE i &lt;= iCount DO              INSERT tstudent4 VALUES (                  inum+i,                  CONCAT(&apos;阿兰&apos;,inum+i),                  IF(CEIL(RAND()*10)%2=0,&apos;男&apos;,&apos;女&apos;),                  RPAD(CONVERT(CEIL(RAND()*1000000000000000000),CHAR(18)),18,&apos;0&apos;),                  CONCAT(CONVERT(CEIL(RAND()*10)+1980,CHAR(4)),&apos;-&apos;,LPAD(CONVERT(CEIL(RAND()*12),                  CHAR(2)),2,&apos;0&apos;),&apos;-&apos;,LPAD(CONVERT(CEIL(RAND()*28),CHAR(2)),2,&apos;0&apos;)),                  CONCAT(CONCAT(&apos;alan&apos;,inum+i),&apos;@hotmail.com&apos;),                  CASE CEIL(RAND()*3) WHEN 1 THEN &apos;网络与网站开发&apos; WHEN 2 THEN &apos;计算机科学技术&apos; ELSE &apos;汇编语言初入门&apos; END,                  NOW(),&apos;河南省郑州市金水区第一实验小学一年级一班&apos;,                  CURRENT_TIMESTAMP(3));              SET i = i + 1;              END WHILE;              commit;          END$$      DELIMITER ;      -------------------------------------------------------------------      DELIMITER $$      CREATE PROCEDURE `upStudent4`(IN iCount INT)      BEGIN              DECLARE    iid INT;              DECLARE    i INT;              SET i =CEIL(RAND()*iCount)+100;              SELECT studentID INTO iid FROM tstudent4 ORDER BY RAND() LIMIT 1;               UPDATE tstudent4 SET cardID=RPAD(CONVERT(CEIL(RAND()*1000000000000000000),CHAR(18)),18,&apos;0&apos;) WHERE studentID between iid and  iid+i;          END$$      DELIMITER ;      -----------------------------------------------------------------------      DELIMITER $$      CREATE  PROCEDURE `teststudent4`()      BEGIN              DECLARE    iid INT;              DECLARE    i INT;              SET i =CEIL(RAND()*200)+100;              CALL `addStudent4`(5000);              CALL `upStudent4`(200);              SELECT min(studentID) INTO iid FROM tstudent4;              DELETE FROM  tstudent4 WHERE studentID between iid and  iid+i;          END$$      DELIMITER ;      ------------------------------------------------------------------------      CREATE  EVENT `example_event2`       ON SCHEDULE EVERY 10 SECOND STARTS CURRENT_TIMESTAMP       ON COMPLETION NOT PRESERVE ENABLE       DO call teststudent4();      ---------------批量建表----------------------------------      DELIMITER $$      CREATE  PROCEDURE `createTables`( IN table_pre VARCHAR(20),IN iCount INT)      BEGIN              DECLARE i INT;              DECLARE table_name VARCHAR(20);                DECLARE sql_text VARCHAR(2000);               SET i=0;              SET table_name=&apos;&apos;;              SET sql_text=&apos;&apos;;              WHILE i&lt;iCount DO                  #IF i&lt;10 THEN SET table_name=CONCAT(table_pre,i);                      #    ELSE SET table_name=CONCAT(table_pre,i);                      #END IF;                  SET table_name=CONCAT(table_pre,i);                  SET sql_text=CONCAT(&apos;CREATE TABLE &apos;, table_name, &apos;(                   id INT(11) NOT NULL COMMENT \&apos;用户id\&apos; AUTO_INCREMENT,                   userName VARCHAR(32)  COMMENT \&apos;用户名\&apos;,                   service INT(11) DEFAULT 0 COMMENT \&apos;服务\&apos;,                   passportUserName VARCHAR(32)  COMMENT \&apos;y\&apos;,                   email  VARCHAR(32) COMMENT \&apos;email\&apos;,                   phone  VARCHAR(15) COMMENT \&apos;电话\&apos;,                       trueName  VARCHAR(12) COMMENT \&apos;真实姓名\&apos;,                       idNumber  VARCHAR(18) COMMENT \&apos;身份证\&apos;,                       nickName  VARCHAR(32) COMMENT \&apos;昵称\&apos;,                       maxMsgId  INT(18) COMMENT \&apos;消息id\&apos;,                       gameIds  VARCHAR(32)DEFAULT null COMMENT \&apos;昵称？\&apos;,                       crmVip  INT(11) COMMENT \&apos;消息id\&apos;,                       status  INT(11) COMMENT \&apos;状态\&apos;,                       updateTime  Date COMMENT \&apos;更新时间\&apos;,                  bigHead  VARCHAR(200)DEFAULT null COMMENT \&apos;bigHead\&apos;,                  smallHead  VARCHAR(200)DEFAULT null COMMENT \&apos;smallHead\&apos;,                  cmos_modify_time datetime(3) NOT NULL DEFAULT CURRENT_TIMESTAMP(3) ON UPDATE CURRENT_TIMESTAMP(3),                  PRIMARY KEY (id),                  KEY idx_cmos_modify_time (cmos_modify_time)                    ) ENGINE=INNODB DEFAULT CHARSET=utf8&apos; );                  SELECT sql_text;                   SET @sql_text=sql_text;                  PREPARE stmt FROM @sql_text;                  EXECUTE stmt;                  DEALLOCATE PREPARE stmt;                    SET i=i+1;              END WHILE;          END$$      DELIMITER ;      ---------------批量删表----------------------------------      DELIMITER $$      CREATE  PROCEDURE `delTables`( IN table_pre VARCHAR(20),IN iCount INT)      BEGIN              DECLARE i INT;              DECLARE table_name VARCHAR(50);                DECLARE sql_text VARCHAR(2000);               SET i=0;              SET table_name=&apos;&apos;;              SET sql_text=&apos;&apos;;              WHILE i&lt;iCount DO                  SET table_name=CONCAT(table_pre,i);                  SET sql_text=CONCAT(&apos;DROP TABLE IF EXISTS &apos;, table_name, &apos;;&apos; );                  SELECT sql_text;                   SET @sql_text=sql_text;                  PREPARE stmt FROM @sql_text;                  EXECUTE stmt;                  DEALLOCATE PREPARE stmt;                    SET i=i+1;              END WHILE;          END$$      DELIMITER ;</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;操作如下： 

      CREATE TABLE `tstudent4` (
        `studentID` int(15) NOT NULL,
        `Sname` varchar(64) DEFAULT NULL,
        
      
    
    </summary>
    
      <category term="数据库" scheme="https://liuhusen.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="存储过程" scheme="https://liuhusen.com/tags/%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B/"/>
    
      <category term="数据库相关操作" scheme="https://liuhusen.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>多线程访问成员变量与局部变量</title>
    <link href="https://liuhusen.com/2018/10/11/%E6%88%90%E5%91%98%E5%8F%98%E9%87%8F%E5%92%8C%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    <id>https://liuhusen.com/2018/10/11/成员变量和局部变量与多线程/</id>
    <published>2018-10-11T08:21:30.000Z</published>
    <updated>2019-03-22T03:14:57.769Z</updated>
    
    <content type="html"><![CDATA[<pre><code>       public class HelloThreadTest    {        public static void main(String[] args)        {            HelloThread r = new HelloThread();            Thread t1 = new Thread(r);            Thread t2 = new Thread(r);            t1.start();            t2.start();        }    }    class HelloThread implements Runnable    {        int i;        @Override        public void run()        {            while (true)            {                System.out.println(&quot;Hello number: &quot; + i++);                try                {                    Thread.sleep((long) Math.random() * 1000);                }                catch (InterruptedException e)                {                    e.printStackTrace();                }                if (50 == i)                {                    break;                }            }        }    }该例子中，HelloThread类实现了Runnable接口，其中run()方法的主要工作是输出&quot;Hello number: &quot;字符串加数字i，并且同时递增i，当i到达50时，退出循环。　　main()方法中生成了一个HelloThread类的对象r，并且利用这个一个对象生成了两个线程。　　程序的执行结果是：顺次打印了0到49的数字，共50个数字。　　这是因为，i是成员变量，则HelloThread的对象r只包含这一个i，两个Thread对象因为由r构造，所以共享了同一个i。　　当我们改变代码如下时（原先的成员变量i被注释掉，增加了方法中的局部变量i）：public class HelloThreadTest    {        public static void main(String[] args)        {            HelloThread r = new HelloThread();            Thread t1 = new Thread(r);            Thread t2 = new Thread(r);            t1.start();            t2.start();        }    }    class HelloThread implements Runnable    {        // int i;        // 若i是成员变量，则HelloThread的对象r只包含这一个i，两个Thread对象因为由r构造，所以共享了同一个i        // 打印结果是0到49的数字        @Override        public void run()        {            int i = 0;            // 每一个线程都会拥有自己的一份局部变量的拷贝            // 线程之间互不影响            // 所以会打印100个数字，0到49每个数字都是两遍            while (true)            {                System.out.println(&quot;Hello number: &quot; + i++);                try                {                    Thread.sleep((long) Math.random() * 1000);                }                catch (InterruptedException e)                {                    e.printStackTrace();                }                if (50 == i)                {                    break;                }            }        }    }    如注释中所述，由于局部变量对于每一个线程来说都有自己的拷贝，所以各个线程之间不再共享同一个变量，    输出结果为100个数字，实际上是两组，每组都是0到49的50个数字，并且两组数字之间随意地穿插在一起。　得到的结论如下：　　如果一个变量是成员变量，那么多个线程对同一个对象的成员变量进行操作时，它们对该成员变量是彼此影响的，也就是说一个线程对成员变量的改变会影响到另一个线程。　　如果一个变量是局部变量，那么每个线程都会有一个该局部变量的拷贝（即便是同一个对象中的方法的局部变量，也会对每一个线程有一个拷贝），一个线程对该局部变量的改变不会影响到其他线程。</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;       public class HelloThreadTest
    {
        public static void main(String[] args)
        {
            HelloThread r = ne
      
    
    </summary>
    
      <category term="关于日志" scheme="https://liuhusen.com/categories/%E5%85%B3%E4%BA%8E%E6%97%A5%E5%BF%97/"/>
    
    
      <category term="多线程" scheme="https://liuhusen.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>Solr单机版服务搭建</title>
    <link href="https://liuhusen.com/2018/10/08/Solr%E5%8D%95%E6%9C%BA%E7%89%88%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/"/>
    <id>https://liuhusen.com/2018/10/08/Solr单机版服务搭建/</id>
    <published>2018-10-08T05:01:30.000Z</published>
    <updated>2019-03-01T06:48:45.132Z</updated>
    
    <content type="html"><![CDATA[<p>   Solr服务搭建<br>      1、solr的环境:solr是Java开发，需要安装JDK，安装环境Linux，需要安装Tomcat。<br>      2、搭建步骤：<br>            第一步： 把solr的压缩包上传到Linux系统<br>            第二步： 解压solr<br>            第三步： 安装Tomcat，解压缩即可。<br>            第四步： 把solr部署到Tomcat下。<br>            第五步： 解压缩war包。启动<br>            第六步： 把/root/solr-4.10.3/example/lib/ext 目录下的所有的jar包，添加到 solr 工程中。<br>            [root@localhost ext]# pwd<br>            /root/solr-4.10.3/example/lib/ext<br>            [root@localhost ext]# cp* /usr/local/solr/tomcat/webapps/solr/WEB-INF/lib/<br>            第七步： 创建一个 solrhome. /exanple/solr 目录就是一个 solrhome. 复制此目录到 /usr/local/solr/solrhome<br>            [root@localhost example]# pwd<br>            /root/solr-4.10.3/example<br>            [root@localhost example]# cp -r solr /usr/local/solr/solrhome<br>            [root@localhost example]#<br>            第八步：关联solr及solrhome。需要修改solr工程的web.xml文件<br>             <img src="/2018/10/08/Solr单机版服务搭建/01.png" alt="你想输入的替代文字"><br>            第九步：启动Tomcat<br>                    <a href="http://192.168.25.154:8080/solr/" target="_blank" rel="noopener">http://192.168.25.154:8080/solr/</a><br>                    和windows下的配置完全一样。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;   Solr服务搭建&lt;br&gt;      1、solr的环境:solr是Java开发，需要安装JDK，安装环境Linux，需要安装Tomcat。&lt;br&gt;      2、搭建步骤：&lt;br&gt;            第一步： 把solr的压缩包上传到Linux系统&lt;br&gt;    
      
    
    </summary>
    
      <category term="服务搭建" scheme="https://liuhusen.com/categories/%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="Solr单机版服务搭建" scheme="https://liuhusen.com/tags/Solr%E5%8D%95%E6%9C%BA%E7%89%88%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>常用的扒拉后台日志操作命令</title>
    <link href="https://liuhusen.com/2018/08/08/%E5%B8%B8%E7%94%A8%E7%9A%84%E6%89%92%E6%8B%89%E5%90%8E%E5%8F%B0%E6%97%A5%E5%BF%97%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4/"/>
    <id>https://liuhusen.com/2018/08/08/常用的扒拉后台日志操作命令/</id>
    <published>2018-08-08T05:01:30.000Z</published>
    <updated>2019-01-18T07:06:06.361Z</updated>
    
    <content type="html"><![CDATA[<p>   翻找环境上的日志：<br>              ll                                     展示目录<br>              cd                                     进入含有日志文件的文件夹目录<br>              tail -200f 文件名                      实时查看200行日志<br>              cat 文件名 | grep “关键字” -A 页数     展示出含有关键字的后面的页数<br>              cat 文件名 | grep “关键字” -B 页数     展示出含有关键字的前面的页数<br>              cat 文件名 | grep “关键字” -C 页数     展示出含有关键字的上下文的页数</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;   翻找环境上的日志：&lt;br&gt;              ll                                     展示目录&lt;br&gt;              cd                                     进入含有日志文
      
    
    </summary>
    
      <category term="关于日志" scheme="https://liuhusen.com/categories/%E5%85%B3%E4%BA%8E%E6%97%A5%E5%BF%97/"/>
    
    
      <category term="生产日志" scheme="https://liuhusen.com/tags/%E7%94%9F%E4%BA%A7%E6%97%A5%E5%BF%97/"/>
    
  </entry>
  
  <entry>
    <title>常见框架单例、多例与线程安全性总结</title>
    <link href="https://liuhusen.com/2018/08/08/%E5%B8%B8%E8%A7%81%E6%A1%86%E6%9E%B6%E5%8D%95%E4%BE%8B%E3%80%81%E5%A4%9A%E4%BE%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7%E6%80%BB%E7%BB%93/"/>
    <id>https://liuhusen.com/2018/08/08/常见框架单例、多例与线程安全性总结/</id>
    <published>2018-08-08T05:01:30.000Z</published>
    <updated>2019-03-22T03:23:51.435Z</updated>
    
    <content type="html"><![CDATA[<pre><code>   单例与多例问题是指，当多个用户访问某个类时，系统是为每个用户创建一个该类实例，还是整个系统无论多少用户访问，只创建一个该类实例。线程安全问题是指，多个用户同时在访问同一个程序时，其对于某一数据的修改，会不会影响到其他用户中的该数据。若没有影响，则是线程安全的;若有可能影响，则是线程不安全的。现在对 HttpServlet、HttpSession、SpingMVC、Struts2 中的 Action、Hibernate 中的 SessionFactory与 Session，进行总结。 (1)HttpServlet    其是单例的。即无论多少用户访问同一个业务，如 LoginServlet，Web 容器只会创建一个该 Servlet 实例。而该实例是允许多用户访问的。    若 Servlet 中包含成员变量，则每个用户对于成员变量的修改，均会影响到其他用户所看到的该变量的值，所以这时是线程不安全的。    若不包含成员变量，则是线程安全的。(2)HttpSession    其是多例的。Web 容器会为每个用户开辟一个 Session，多个用户会有多个 Session。而每个用户只能访问自己的 Session。    所以，对于 Session 来说，就不存在并发访问的情况，也就不存在线程安全的问题了。所以可以说是线程安全的。(3)SpingMVC Controller    Spring MVC Controller默认是单例的：    单例的原因有二：    1、为了性能。    2、不需要多例。    如果需要多例，则需要在Controller类上加注解 @Scope(“prototype”)(4)Struts2 的 Action    其是多例的。对于同一个业务，例如 LoginAction，系统会为每一个用户创建一个LoginAction 的实例，    并使其成员变量 username 与 password 接收用户 交的数据。同一用户只能访问自己的 Action。    所以，对于 Action 来说，就不存在并发访问的情况，也就不存在线程安全的问题了。所以可以说是线程安全的。 (5)Hibernate 的 SessionFactory    其是单例的。无论多少用户访问该项目，系统只会创建一个 SessionFactory 对象，即这个对象是可以被所有用户访问的。    SessionFactory实现类中所包含的成员变量基本都是 final常量，即任何用户均不能修改。所以，也就不存在用户的修改对其他用户的影响问题了，所以是线程安全的。 (6)Hibernate 的 Session    其是多例的。系统会为每个用户创建一个 Sessio。    Session 的实现类中定义了很多的非 final 成员变量，一个事务对成员变量所做的修改，会影响到另一个事务对同一数据的访问结果，所以是线程不安全的。 </code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;   单例与多例问题是指，当多个用户访问某个类时，系统是为每个用户创建一个该类实例，还是整个系统无论多少用户访问，只创建一个该类实例。

线程安全问题是指，多个用户同时在访问同一个程序时，其对于某一数据的修改，会不会影响到其他用户中的该数据。若没有影响，则是
      
    
    </summary>
    
      <category term="关于日志" scheme="https://liuhusen.com/categories/%E5%85%B3%E4%BA%8E%E6%97%A5%E5%BF%97/"/>
    
    
      <category term="多例，多线程" scheme="https://liuhusen.com/tags/%E5%A4%9A%E4%BE%8B%EF%BC%8C%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>redis的安装与集群搭建</title>
    <link href="https://liuhusen.com/2018/02/08/redis%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>https://liuhusen.com/2018/02/08/redis的安装与集群搭建/</id>
    <published>2018-02-08T05:01:30.000Z</published>
    <updated>2019-02-28T11:40:30.824Z</updated>
    
    <content type="html"><![CDATA[<p>   Redis是C语言开发的。<br>   安装Redis需要C语言的编译环境。如果没有gcc 需要在线安装。 Yum install gcc-c++</p><p>   安装步骤：<br>        第一步： Redis的源码包上传到Linux系统。<br>        第二步： 解压缩Redis。<br>        第三步： 编译  make<br>        第四步： 安装  make install PREFIX=/usr/local/redis</p><p>   连接Redis：<br>        1.Redis的启动：<br>            前端启动：[root@localhost bin]# ./redis-server<br>            后台启动： 把 /root/redis-3.0.0/redis.conf 复制到 /usr/local/redis/bin目录下<br>                      [root@localhost bin]# cp redis.conf  /usr/local/redis/bin/<br>            修改配置文件：<br>             <img src="/2018/02/08/redis的安装与集群搭建/01.png" alt="你想输入的替代文字"><br>             [root@localhost bin]# ./redis-server redis.conf<br>             查看Redis进程：<br>                            [root@localhost bin]# ps aux|grep redis<br>                            root      5190  0.1  0.3  33936  1712 ?        Ssl  18:23   0:00 ./redis-server *:6379<br>                            root      5196  0.0  0.1   4356   728 pts/0    S+   18:24   0:00 grep redis<br>                            [root@localhost bin]#<br>        2.Redis-cli<br>            [root@localhost bin]# ./redis-cli<br>            默认连接localhost运行在6379端口的Redis服务<br>            [root@localhost bin]# ./redis-cli -h 192.168.25.153 -p 6379<br>            -h : 连接的服务器地址<br>            -p : 服务的端口号</p><pre><code>3.Redis五种数据类型   String : key-value (做缓存)     Hash ：key-fields-values (做缓存)     List : 有顺序可重复      Set ：无顺序，不能重复SortedSet(zset) : 有顺序，不能重复4.Redis集群的搭建   （1） redis-cluster 架构图        ![你想输入的替代文字](redis的安装与集群搭建/02.png)        架构细节：             1.所有的Redis节点彼此互联（ping-pong机制），内部使用二进制协议优化传输速度和带宽             2.节点的fail是通过集群中超过半数的节点检测失效时才生效             3.客户端与Redis节点直连，不需要中间proxy层，客户端不需要连接集群所有节点，               连接集群中任何一个可用节点即可             4.redis-cluster 把所有的物理节点映射到 [0-16383] slot上，cluster负责维护               node&lt;-&gt;slot&lt;-&gt;node               Redis 集群中内置了 16384 个哈希槽，当需要在 redis集群中放置一个 key-value 时，               redis 先对 key 使用 crc16算法算出一个结果，然后把结果对 16384 求余，这样每个 key 都               会对应一个编号在 0-16383 之间的哈希槽，redis会根据节点数量大致均等的将哈希槽映射到               不同的节点   （2） 1、 使用ruby脚本搭建集群。需要ruby的运行环境。             安装 ruby             yum install ruby             yum install rubygems         2、 安装 ruby 脚本运行使用的包             [root@localhost ~]#  gem install redis-3.0.0.gem             Successfully installed redis-3.0.0             1 gem installed             Installing ri documentation for redis-3.0.0...             Installing RDoc documentation for redis-3.0.0...             [root@localhost ~]#              [root@localhost ~]#  redis-3.0.0/src             [root@localhost ~]#  ll*.rb             -rwxrwxr-x. 1 root root 48141 Apr  1  2015 redis-trib.rb         3、 搭建步骤             需要6台redis服务器。搭建伪分布式。             需要6个redis实例。             需要运行在不同的端口 7001-7006             第一步：创建6个redis实例，每个实例运行在不同的端口。需要修改redis.conf配置文件。                     配置文件中还需要把 cluster-enabled yes 前的注释去掉                     ![你想输入的替代文字](redis的安装与集群搭建/03.png)             第二步：启动每个redis实例。             第三步：使用ruby脚本搭建集群。                     ./redis-trib.rb create --replicas 1 192.168.25.153:7001 192.168.25.153:7002                       192.168.25.153:7003 192.168.25.153:7004 192.168.25.153:7005  192.168.25.153:7006                      创建关闭集群的脚本：                       [root@localhost redis-cluster]# vim shutdow-all.sh                      redis01/redis-cli -p 7001 shutdown                      redis01/redis-cli -p 7002 shutdown                      redis01/redis-cli -p 7003 shutdown                      redis01/redis-cli -p 7004 shutdown                      redis01/redis-cli -p 7005 shutdown                      redis01/redis-cli -p 7006 shutdown                      [root@localhost redis-cluster]# chomd u+x shutdown-all.sh                      [root@localhost redis-cluster]# ./redis-trib.rb create --replicas 1 192.168.25.153:7001                      192.168.25.153:7002 192.168.25.153:7003 192.168.25.153:7004 192.168.25.153:7005                      192.168.25.153:7006                      &gt;&gt;&gt; Creating cluster                      Connecting to node 192.168.25.153:7001: OK                      Connecting to node 192.168.25.153:7002: OK                      Connecting to node 192.168.25.153:7003: OK                      Connecting to node 192.168.25.153:7004: OK                      Connecting to node 192.168.25.153:7005: OK                      Connecting to node 192.168.25.153:7006: OK                      &gt;&gt;&gt; Performing hash slots allocation on 6 nodes...                      Using 3 masters:                      192.168.25.153:7001                      192.168.25.153:7002                      192.168.25.153:7003                      Adding replica 192.168.25.153:7004 to 192.168.25.153:7001                      Adding replica 192.168.25.153:7005 to 192.168.25.153:7002                      Adding replica 192.168.25.153:7006 to 192.168.25.153:7003                      M: 2e48ae301e9c32b04a7d4d92e15e98e78de8c1f3 192.168.25.153:7001                         slots:0-5460 (5461 slots) master                      M: 8cd93a9a943b4ef851af6a03edd699a6061ace01 192.168.25.153:7002                         slots:5461-10922 (5462 slots) master                      M: 2935007902d83f20b1253d7f43dae32aab9744e6 192.168.25.153:7003                         slots:10923-16383 (5461 slots) master                      S: 74f9d9706f848471583929fc8bbde3c8e99e211b 192.168.25.153:7004                         replicates 2e48ae301e9c32b04a7d4d92e15e98e78de8c1f3                      S: 42cc9e25ebb19dda92591364c1df4b3a518b795b 192.168.25.153:7005                         replicates 8cd93a9a943b4ef851af6a03edd699a6061ace01                      S: 8b1b11d509d29659c2831e7a9f6469c060dfcd39 192.168.25.153:7006                         replicates 2935007902d83f20b1253d7f43dae32aab9744e6                      Can I set the above configuration? (type &apos;yes&apos; to accept): yes                      &gt;&gt;&gt; Nodes configuration updated                      &gt;&gt;&gt; Assign a different config epoch to each node                      &gt;&gt;&gt; Sending CLUSTER MEET messages to join the cluster                      Waiting for the cluster to join.....                      &gt;&gt;&gt; Performing Cluster Check (using node 192.168.25.153:7001)                      M: 2e48ae301e9c32b04a7d4d92e15e98e78de8c1f3 192.168.25.153:7001                         slots:0-5460 (5461 slots) master                      M: 8cd93a9a943b4ef851af6a03edd699a6061ace01 192.168.25.153:7002                         slots:5461-10922 (5462 slots) master                      M: 2935007902d83f20b1253d7f43dae32aab9744e6 192.168.25.153:7003                         slots:10923-16383 (5461 slots) master                      M: 74f9d9706f848471583929fc8bbde3c8e99e211b 192.168.25.153:7004                         slots: (0 slots) master                         replicates 2e48ae301e9c32b04a7d4d92e15e98e78de8c1f3                      M: 42cc9e25ebb19dda92591364c1df4b3a518b795b 192.168.25.153:7005                         slots: (0 slots) master                         replicates 8cd93a9a943b4ef851af6a03edd699a6061ace01                      M: 8b1b11d509d29659c2831e7a9f6469c060dfcd39 192.168.25.153:7006                         slots: (0 slots) master                         replicates 2935007902d83f20b1253d7f43dae32aab9744e6                      [OK] All nodes agree about slots configuration.                      &gt;&gt;&gt; Check for open slots...                      &gt;&gt;&gt; Check slots coverage...                      [OK] All 16384 slots covered.                      [root@localhost redis-cluster]# 5、 集群的使用方法    Redis-cli 连接集群    。    [root@localhost redis-cluster]# redis01/redis-cli -p 7002 -c    -c: 代表连接的是redis集群</code></pre><p>   （3） Jedis<br>         需要把jedis依赖的jar包添加到工程中。Maven工程中需要把jedis的坐标添加到依赖。<br>         推荐添加到服务层。Taotao-content-Service 工程中</p><pre><code>     1. 连接单机版        第一步：创建一个Jedis对象。需要指定服务端的IP及端口。        第二步：使用Jedis对象操作数据库，每个Jedis命令对应一个方法。        第三步：打印结果。        第四步：关闭Jedis        代码如下：        @Test            public void testJedis() throws Exception {                // 第一步：创建一个Jedis对象。需要指定服务端的ip及端口。                Jedis jedis = new Jedis(&quot;192.168.25.153&quot;, 6379);                // 第二步：使用Jedis对象操作数据库，每个redis命令对应一个方法。                String result = jedis.get(&quot;hello&quot;);                // 第三步：打印结果。                System.out.println(result);                // 第四步：关闭Jedis                jedis.close();            }          2、连接单机版使用连接池          第一步： 创建一个JedisPool对象。需要指定服务器的IP及端口。          第二步： 从JedisPool中获取Jedis对象。          第三步： 使用Jedis操作redis服务器          第四步： 使用完毕后关闭jedis对象，连接池回收资源。          第五步： 关闭JedisPool对象。          代码如下：            @Test            public void testJedisPool() throws Exception {                // 第一步：创建一个JedisPool对象。需要指定服务端的ip及端口。                JedisPool jedisPool = new JedisPool(&quot;192.168.25.153&quot;, 6379);                // 第二步：从JedisPool中获得Jedis对象。                Jedis jedis = jedisPool.getResource();                // 第三步：使用Jedis操作redis服务器。                jedis.set(&quot;jedis&quot;, &quot;test&quot;);                String result = jedis.get(&quot;jedis&quot;);                System.out.println(result);                // 第四步：操作完毕后关闭jedis对象，连接池回收资源。                jedis.close();                // 第五步：关闭JedisPool对象。                jedisPool.close();            }           3、连接集群版         第一步: 使用JedisCluster对象。需要一个 Set&lt;HostAndPost&gt; 参数。Redis 节点列表。         第二步：直接使用JedisCluster对象操作redis。在系统中单例存在。         第三步：打印结果。                第四步：系统关闭前，关闭JedisCluster对象。         代码如下：        @Test        public void testJedisCluster() throws Exception {            // 第一步：使用JedisCluster对象。需要一个Set&lt;HostAndPort&gt;参数。Redis节点的列表。            Set&lt;HostAndPort&gt; nodes = new HashSet&lt;&gt;();            nodes.add(new HostAndPort(&quot;192.168.25.153&quot;, 7001));            nodes.add(new HostAndPort(&quot;192.168.25.153&quot;, 7002));            nodes.add(new HostAndPort(&quot;192.168.25.153&quot;, 7003));            nodes.add(new HostAndPort(&quot;192.168.25.153&quot;, 7004));            nodes.add(new HostAndPort(&quot;192.168.25.153&quot;, 7005));            nodes.add(new HostAndPort(&quot;192.168.25.153&quot;, 7006));            JedisCluster jedisCluster = new JedisCluster(nodes);            // 第二步：直接使用JedisCluster对象操作redis。在系统中单例存在。            jedisCluster.set(&quot;hello&quot;, &quot;100&quot;);            String result = jedisCluster.get(&quot;hello&quot;);            // 第三步：打印结果            System.out.println(result);            // 第四步：系统关闭前，关闭JedisCluster对象。            jedisCluster.close();        }    （4）、实际使用案例：在实际业务逻辑的添加缓存            1、 接口封装            常用的操作redis的方法提取出一个接口，分别对应单机版和集群版创建两个实现类。        2、 单机版接口定义            public interface JedisClient {                String set(String key, String value);                String get(String key);                Boolean exists(String key);                Long expire(String key, int seconds);                Long ttl(String key);                Long incr(String key);                Long hset(String key, String field, String value);                String hget(String key, String field);                Long hdel(String key, String... field);            }            3、 单机版实现类             public class JedisClientPool implements JedisClient {                @Autowired                private JedisPool jedisPool;                @Override                public String set(String key, String value) {                    Jedis jedis = jedisPool.getResource();                    String result = jedis.set(key, value);                    jedis.close();                    return result;                }                @Override                public String get(String key) {                    Jedis jedis = jedisPool.getResource();                    String result = jedis.get(key);                    jedis.close();                    return result;                }                @Override                public Boolean exists(String key) {                    Jedis jedis = jedisPool.getResource();                    Boolean result = jedis.exists(key);                    jedis.close();                    return result;                }                @Override                public Long expire(String key, int seconds) {                    Jedis jedis = jedisPool.getResource();                    Long result = jedis.expire(key, seconds);                    jedis.close();                    return result;                }                @Override                public Long ttl(String key) {                    Jedis jedis = jedisPool.getResource();                    Long result = jedis.ttl(key);                    jedis.close();                    return result;                }                @Override                public Long incr(String key) {                    Jedis jedis = jedisPool.getResource();                    Long result = jedis.incr(key);                    jedis.close();                    return result;                }                @Override                public Long hset(String key, String field, String value) {                    Jedis jedis = jedisPool.getResource();                    Long result = jedis.hset(key, field, value);                    jedis.close();                    return result;                }                @Override                public String hget(String key, String field) {                    Jedis jedis = jedisPool.getResource();                    String result = jedis.hget(key, field);                    jedis.close();                    return result;                }                @Override                public Long hdel(String key, String... field) {                    Jedis jedis = jedisPool.getResource();                    Long result = jedis.hdel(key, field);                    jedis.close();                    return result;                }            }                    配置applicationContext-redis.xml         &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;            &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;                xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot;                xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;                xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;                xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans4.2.xsd                http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context4.2.xsd                http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx4.2.xsd                http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util4.2.xsd&quot;&gt;                &lt;!--配置单机版的连接--&gt;                &lt;bean id=&quot;jedisPool&quot; class=&quot;redis.client.jedis.JedisPool&quot;&gt;                      &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.153&quot;&gt; &lt;/constructor-arg&gt;                      &lt;constructor-arg name=&quot;port&quot; value=&quot;6379&quot;&gt; &lt;/constructor-arg&gt;                &lt;/bean&gt;                &lt;bean id=&quot;jedisClientPool&quot; class=&quot;com.taotao.jedis.JedisClientPool&quot; /&gt;            &lt;/beans&gt;        集群版实现类：           代码如下：            package com.taotao.jedis;                import org.springframework.beans.factory.annotation.Autowired;                import redis.clients.jedis.JedisCluster;                public class JedisClientCluster implements JedisClient {                    @Autowired                    private JedisCluster jedisCluster;                    @Override                    public String set(String key, String value) {                        return jedisCluster.set(key, value);                    }                    @Override                    public String get(String key) {                        return jedisCluster.get(key);                    }                    @Override                    public Boolean exists(String key) {                        return jedisCluster.exists(key);                    }                    @Override                    public Long expire(String key, int seconds) {                        return jedisCluster.expire(key, seconds);                    }                    @Override                    public Long ttl(String key) {                        return jedisCluster.ttl(key);                    }                    @Override                    public Long incr(String key) {                        return jedisCluster.incr(key);                    }                    @Override                    public Long hset(String key, String field, String value) {                        return jedisCluster.hset(key, field, value);                    }                    @Override                    public String hget(String key, String field) {                        return jedisCluster.hget(key, field);                    }                    @Override                    public Long hdel(String key, String... field) {                        return jedisCluster.hdel(key, field);                    }                }            Spring的配置：                 &lt;!-- 集群版的配置 --&gt;                        &lt;bean id=&quot;jedisCluster&quot; class=&quot;redis.clients.jedis.JedisCluster&quot;&gt;                            &lt;constructor-arg&gt;                               &lt;set&gt;                                    &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;                                          &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.153&quot;&gt; &lt;/constructor-arg&gt;                                          &lt;constructor-arg name=&quot;port&quot; value=&quot;7001&quot;&gt; &lt;/constructor-arg&gt;                                    &lt;/beans&gt;                                    &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;                                          &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.153&quot;&gt; &lt;/constructor-arg&gt;                                          &lt;constructor-arg name=&quot;port&quot; value=&quot;7002&quot;&gt; &lt;/constructor-arg&gt;                                    &lt;/beans&gt;                                    &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;                                        &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.153&quot;&gt;&lt;/constructor-arg&gt;                                        &lt;constructor-arg name=&quot;port&quot; value=&quot;7003&quot;&gt;&lt;/constructor-arg&gt;                                    &lt;/bean&gt;                                    &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;                                        &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.153&quot;&gt;&lt;/constructor-arg&gt;                                        &lt;constructor-arg name=&quot;port&quot; value=&quot;7004&quot;&gt;&lt;/constructor-arg&gt;                                    &lt;/bean&gt;                                    &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;                                        &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.153&quot;&gt;&lt;/constructor-arg&gt;                                        &lt;constructor-arg name=&quot;port&quot; value=&quot;7005&quot;&gt;&lt;/constructor-arg&gt;                                    &lt;/bean&gt;                                    &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;                                        &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.153&quot;&gt;&lt;/constructor-arg&gt;                                        &lt;constructor-arg name=&quot;port&quot; value=&quot;7006&quot;&gt;&lt;/constructor-arg&gt;                                    &lt;/bean&gt;                                &lt;/set&gt;                            &lt;/constructor-arg&gt;                        &lt;/bean&gt;                        &lt;bean id=&quot;jedisClientCluster&quot; class=&quot;com.taotao.jedis.JedisClientCluster&quot; /&gt;                        注意： 单机版和集群版不能共存，使用单机版时注释集群版的配置。使用集群版，把单机版注释。                        工作中常用的业务：（注意：添加缓存时不能影响正常业务逻辑）                            1.大数据量查询时:                                  查数据库之前先查询缓存，查到结果就直接响应结果，查不到则                                  缓存中没有，需要查询数据库，把查询结果添加到缓存中。                                  还需要考虑到一点  ： 缓存同步-- 对内容信息做增删改查操作后把对应缓存删除即可。</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;   Redis是C语言开发的。&lt;br&gt;   安装Redis需要C语言的编译环境。如果没有gcc 需要在线安装。 Yum install gcc-c++&lt;/p&gt;
&lt;p&gt;   安装步骤：&lt;br&gt;        第一步： Redis的源码包上传到Linux系统。&lt;br&gt;    
      
    
    </summary>
    
      <category term="redis" scheme="https://liuhusen.com/categories/redis/"/>
    
    
      <category term="redis" scheme="https://liuhusen.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>关于Hexo更换git账号的步骤记录</title>
    <link href="https://liuhusen.com/2017/06/08/%E5%85%B3%E4%BA%8EHexo%E6%9B%B4%E6%8D%A2git%E8%B4%A6%E5%8F%B7%E7%9A%84%E6%AD%A5%E9%AA%A4%E8%AE%B0%E5%BD%95/"/>
    <id>https://liuhusen.com/2017/06/08/关于Hexo更换git账号的步骤记录/</id>
    <published>2017-06-08T05:01:30.000Z</published>
    <updated>2019-04-02T02:42:14.207Z</updated>
    
    <content type="html"><![CDATA[<pre><code>操作如下：   1.编辑_config.yml(在\hexo下)。你在部署时，要把下面的都换成你的账号名。      deploy:        type: git        repo: git@github.com:liuhusen/liuhusen.github.io.git          branch: master   2.更换你本地的git用户名和邮箱，命令如下         查看当前用户名：git config user.name         查看当前邮箱（注册git账号的邮箱）：git config user.email         更改用户名：git config --global user.name &quot;liuhusen&quot;         更改邮箱：git config --global user.email &quot;l_Striving@163.com&quot;  3.生成你的ssh密钥，命令如下：        生成密钥： ssh-keygen -t rsa -C &quot;l_Striving@163.com&quot;        三次回车，设置密码为空        将生成的C:\Users\Administrator.ssh目录下的id_rsa.pub添加到github上  4. 清理：hexo c     生成静态资源： hexo g      推送到git上：  hexo d     重新在git上设置你的访问域名     设置完毕，大功告成！</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;操作如下： 
  1.编辑_config.yml(在\hexo下)。你在部署时，要把下面的都换成你的账号名。
      deploy:
        type: git
        repo: git@github.com:liuhusen/liuh
      
    
    </summary>
    
      <category term="其他" scheme="https://liuhusen.com/categories/%E5%85%B6%E4%BB%96/"/>
    
    
      <category term="hexo" scheme="https://liuhusen.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>简单有效的页面防止重复提交的操作</title>
    <link href="https://liuhusen.com/2017/06/08/%E7%AE%80%E5%8D%95%E6%9C%89%E6%95%88%E7%9A%84%E9%A1%B5%E9%9D%A2%E9%98%B2%E6%AD%A2%E9%87%8D%E5%A4%8D%E6%8F%90%E4%BA%A4%E7%9A%84%E6%93%8D%E4%BD%9C/"/>
    <id>https://liuhusen.com/2017/06/08/简单有效的页面防止重复提交的操作/</id>
    <published>2017-06-08T05:01:30.000Z</published>
    <updated>2018-10-31T07:41:51.026Z</updated>
    
    <content type="html"><![CDATA[<pre><code>操作如下：     var isSubmit = true; // 在js顶部定义全局变量    if(isSubmit){       save();    }else{       crossAPI.tips(&quot;请勿重复提交数据！&quot;,3000);       return false;    }    var save = function () {          isSubmit = false; // 进入方法后 isSubmit 置为 false，在后续的点击提交时，便不会执行save方法          。。。          。。。 // 此处为你自己的执行保存的方法          if( 保存成功 ){             关闭数据新增页面，并刷新查询页面的查询          }else{             // 保存失败，则页面提醒保存失败             isSubmit = true;  // isSubmit 置为 true ,用以再次提交当前数据使用          }    }</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;操作如下： 

    var isSubmit = true; // 在js顶部定义全局变量

    if(isSubmit){
       save();
    }else{
       crossAPI.tips(&amp;quot;请勿重复提交数据！
      
    
    </summary>
    
      <category term="javascript" scheme="https://liuhusen.com/categories/javascript/"/>
    
    
      <category term="javascript页面效果" scheme="https://liuhusen.com/tags/javascript%E9%A1%B5%E9%9D%A2%E6%95%88%E6%9E%9C/"/>
    
      <category term="防止重复提交" scheme="https://liuhusen.com/tags/%E9%98%B2%E6%AD%A2%E9%87%8D%E5%A4%8D%E6%8F%90%E4%BA%A4/"/>
    
  </entry>
  
  <entry>
    <title>MySQL的表增删字段和增删索引</title>
    <link href="https://liuhusen.com/2017/05/26/MySQL%E7%9A%84%E8%A1%A8%E5%A2%9E%E5%88%A0%E5%AD%97%E6%AE%B5%E5%92%8C%E5%A2%9E%E5%88%A0%E7%B4%A2%E5%BC%95/"/>
    <id>https://liuhusen.com/2017/05/26/MySQL的表增删字段和增删索引/</id>
    <published>2017-05-26T11:57:47.000Z</published>
    <updated>2018-10-28T19:13:31.613Z</updated>
    
    <content type="html"><![CDATA[<pre><code>表添加字段： ALTER TABLE 表名 ADD COLUMN 表字段 varchar(50) DEFAULT NULL COMMENT &apos;字段描述&apos;;表删除字段： ALTER TABLE 表名 DROP COLUMN  表字段 ;字段建唯一索引：create index idx_province_id on 表名 (表字段 );                               上为索引                create index 字段的索引 on 表名 (表字段 );               删除字段的索引：alter table 表名 drop index idx_province_id ;                                        上为索引                alter table 表名 drop 字段的索引 ;</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;表添加字段： ALTER TABLE 表名 ADD COLUMN 表字段 varchar(50) DEFAULT NULL COMMENT &amp;apos;字段描述&amp;apos;;

表删除字段： ALTER TABLE 表名 DROP COLUMN  表字段 ;
      
    
    </summary>
    
      <category term="mysql" scheme="https://liuhusen.com/categories/mysql/"/>
    
    
      <category term="MySQL" scheme="https://liuhusen.com/tags/MySQL/"/>
    
      <category term="增删字段" scheme="https://liuhusen.com/tags/%E5%A2%9E%E5%88%A0%E5%AD%97%E6%AE%B5/"/>
    
      <category term="增删索引" scheme="https://liuhusen.com/tags/%E5%A2%9E%E5%88%A0%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
  <entry>
    <title>接口传输时对乱码的处理</title>
    <link href="https://liuhusen.com/2017/05/26/%E6%8E%A5%E5%8F%A3%E4%BC%A0%E8%BE%93%E6%97%B6%E5%AF%B9%E4%B9%B1%E7%A0%81%E7%9A%84%E5%A4%84%E7%90%86/"/>
    <id>https://liuhusen.com/2017/05/26/接口传输时对乱码的处理/</id>
    <published>2017-05-26T11:57:47.000Z</published>
    <updated>2019-04-02T02:51:36.941Z</updated>
    
    <content type="html"><![CDATA[<pre><code>传输前编码：// 先对用户名进行解码得到%E7%8E%8B%E6%8C%AF%E5%9B%BD 这样的形式username = URLEncoder.encode(username, &quot;ISO-8859-1&quot;);获取后解码：username = URLDecoder.decode(username, &quot;UTF-8&quot;);System.out.println(&quot;乱码解决后用户名：&quot; + username)</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;传输前编码：
// 先对用户名进行解码得到%E7%8E%8B%E6%8C%AF%E5%9B%BD 这样的形式
username = URLEncoder.encode(username, &amp;quot;ISO-8859-1&amp;quot;);

获取后解码：
us
      
    
    </summary>
    
      <category term="接口传输" scheme="https://liuhusen.com/categories/%E6%8E%A5%E5%8F%A3%E4%BC%A0%E8%BE%93/"/>
    
    
      <category term="接口传输" scheme="https://liuhusen.com/tags/%E6%8E%A5%E5%8F%A3%E4%BC%A0%E8%BE%93/"/>
    
      <category term="post请求传输" scheme="https://liuhusen.com/tags/post%E8%AF%B7%E6%B1%82%E4%BC%A0%E8%BE%93/"/>
    
      <category term="get请求传输" scheme="https://liuhusen.com/tags/get%E8%AF%B7%E6%B1%82%E4%BC%A0%E8%BE%93/"/>
    
  </entry>
  
  <entry>
    <title>MySQL的表以及数据备份</title>
    <link href="https://liuhusen.com/2017/05/26/MySQL%E7%9A%84%E8%A1%A8%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD/"/>
    <id>https://liuhusen.com/2017/05/26/MySQL的表以及数据备份/</id>
    <published>2017-05-26T11:57:47.000Z</published>
    <updated>2018-10-28T19:14:11.519Z</updated>
    
    <content type="html"><![CDATA[<p>   备份表方法：  此方法索引和increment值也会同步</p><pre><code>CREATE TABLE tb_cab_bak LIKE tb_cab; // 同步建表INSERT INTO tb_cab_bak SELECT * FROM tb_cab；// 同步数据</code></pre><p>   若只复制表中的部分内容的同时定义表中的字段信息：<br>                 CREATE TABLE tb_cab_bak<br>                  (<br>                  – 对copy的表中的ID进行主键约束<br>                 ID INTEGER NOT NULL AUTO_INCREMENT PRIMARY KEY<br>                   )<br>                 AS<br>                 ( SELECT ID,SNAME,SCORE FROM tb_cab_bak );</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;   备份表方法：  此方法索引和increment值也会同步&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE TABLE tb_cab_bak LIKE tb_cab; // 同步建表

INSERT INTO tb_cab_bak SELECT * FROM tb_cab；
      
    
    </summary>
    
      <category term="mysql" scheme="https://liuhusen.com/categories/mysql/"/>
    
    
      <category term="MySQL" scheme="https://liuhusen.com/tags/MySQL/"/>
    
      <category term="数据备份" scheme="https://liuhusen.com/tags/%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD/"/>
    
  </entry>
  
  <entry>
    <title>自学编程成功概率有多少可能</title>
    <link href="https://liuhusen.com/2017/05/26/%E5%85%B3%E4%BA%8E/"/>
    <id>https://liuhusen.com/2017/05/26/关于/</id>
    <published>2017-05-26T11:57:47.000Z</published>
    <updated>2018-10-25T06:24:46.244Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
      <category term="档案" scheme="https://liuhusen.com/categories/%E6%A1%A3%E6%A1%88/"/>
    
    
      <category term="编程" scheme="https://liuhusen.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="感悟" scheme="https://liuhusen.com/tags/%E6%84%9F%E6%82%9F/"/>
    
  </entry>
  
</feed>
